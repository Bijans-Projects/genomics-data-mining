[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Genomics Data Mining",
    "section": "",
    "text": "TECHNNICAL\nWe expect a basic understanding of programming (we use Python, but any programming language will do). Only functions that are created within this project will have documentation, otherwise you are expected to be able to read and understand what they are doing through their own official documentation.\nBIOLOGY\nWe are only looking at human biology, and expect you to know at least the following:\n\nGenome\n\nThink of this as an entire library of all the pieces and instructions for a human\nThe collection of all chromosomes\n\nChromosome\n\nThink of this as the organization method of the library\nOne single DNA molecule, packaged tightly\n\nGene\n\nThink of this as individual recipes that make something, but just the ingredients list\nA section of DNA (or a section of RNA) that does something\n\nDNA\n\nThink of this as the letters that are used for writing everything\nMade up of four chemicals\nIs a double-helix (i.e., two-strands)\nDNA is ‚Äúthe original‚Äù plans, so to keep them safe, copies are made; Transcription\nCopies are then used to do what the plans say\n\nRNA\n\nThink of this as the copy ??? Not sure what to put here\nRNA is one-side of the DNA strand\nIt is how instructions can be carried out; Instructions include ‚Äúmake a protein‚Äù; Translation\n\nmRNA\nProtein\n\nProteins are\n\nHumans are essentially meat-bags\nWe have different kinds of ‚Äúmeat‚Äù but they‚Äôre all made up of cells\nThe types of cells and types of meats are ‚ÄúCellular Biology‚Äù - we‚Äôre not going to focus on this, at all\nWe are going to be looking at things that are smaller than cells, and basically how they impact cells (which then impact other things)"
  },
  {
    "objectID": "index.html#expectations",
    "href": "index.html#expectations",
    "title": "Genomics Data Mining",
    "section": "",
    "text": "TECHNNICAL\nWe expect a basic understanding of programming (we use Python, but any programming language will do). Only functions that are created within this project will have documentation, otherwise you are expected to be able to read and understand what they are doing through their own official documentation.\nBIOLOGY\nWe are only looking at human biology, and expect you to know at least the following:\n\nGenome\n\nThink of this as an entire library of all the pieces and instructions for a human\nThe collection of all chromosomes\n\nChromosome\n\nThink of this as the organization method of the library\nOne single DNA molecule, packaged tightly\n\nGene\n\nThink of this as individual recipes that make something, but just the ingredients list\nA section of DNA (or a section of RNA) that does something\n\nDNA\n\nThink of this as the letters that are used for writing everything\nMade up of four chemicals\nIs a double-helix (i.e., two-strands)\nDNA is ‚Äúthe original‚Äù plans, so to keep them safe, copies are made; Transcription\nCopies are then used to do what the plans say\n\nRNA\n\nThink of this as the copy ??? Not sure what to put here\nRNA is one-side of the DNA strand\nIt is how instructions can be carried out; Instructions include ‚Äúmake a protein‚Äù; Translation\n\nmRNA\nProtein\n\nProteins are\n\nHumans are essentially meat-bags\nWe have different kinds of ‚Äúmeat‚Äù but they‚Äôre all made up of cells\nThe types of cells and types of meats are ‚ÄúCellular Biology‚Äù - we‚Äôre not going to focus on this, at all\nWe are going to be looking at things that are smaller than cells, and basically how they impact cells (which then impact other things)"
  },
  {
    "objectID": "index.html#setup",
    "href": "index.html#setup",
    "title": "Genomics Data Mining",
    "section": "Setup",
    "text": "Setup\n\nhtml`\n&lt;div class=\"section-div\"&gt;\n  &lt;div class=\"current\"&gt;Setup&lt;/div&gt;\n  &lt;div&gt;Data Acquisition&lt;/div&gt;\n  &lt;div&gt;Data Understanding&lt;/div&gt;\n  &lt;div&gt;Data Cleaning&lt;/div&gt;\n  &lt;div&gt;Dimension Reduction&lt;/div&gt;\n  &lt;div&gt;Statistical Modelling&lt;/div&gt;\n  &lt;div&gt;Conclusions&lt;/div&gt;\n&lt;/div&gt;\n`\n\n\n\n\n\n\nEstablishing a reproducible analysis environment.\n\n# Used if needed to debut environment issues\n\nimport sys, os, site\nprint(\"exe:\", sys.executable)\nprint(\"ver:\", sys.version)\nprint(\"prefix:\", sys.prefix)\nprint(\"base_prefix:\", sys.base_prefix)\nprint(\"cwd:\", os.getcwd())\nprint(\"usersite:\", site.getusersitepackages())\n\n\nfor k in [\"PYTHONHOME\", \"PYTHONPATH\", \"CONDA_PREFIX\", \"VIRTUAL_ENV\"]:\n    print(k, \"=\", os.environ.get(k))\n\n\nimport os, shutil, subprocess\nfrom pathlib import Path\n\nprint(\"sys.executable:\", sys.executable)\nprint(\"CONDA_PREFIX:\", os.getenv(\"CONDA_PREFIX\"))\nprint(\"CONDA_PREFIX_1:\", os.getenv(\"CONDA_PREFIX_1\"))\nprint(\"CONDA_EXE:\", os.getenv(\"CONDA_EXE\"))\nprint(\"which conda:\", shutil.which(\"conda\"))\n\n# Try common locations\ncandidates = []\nif os.getenv(\"CONDA_EXE\"):\n    candidates.append(os.getenv(\"CONDA_EXE\"))\nif os.getenv(\"CONDA_PREFIX_1\"):\n    candidates.append(str(Path(os.getenv(\"CONDA_PREFIX_1\")) / \"Scripts\" / \"conda.exe\"))\nif os.getenv(\"CONDA_ROOT\"):\n    candidates.append(str(Path(os.getenv(\"CONDA_ROOT\")) / \"Scripts\" / \"conda.exe\"))\n\nprint(\"\\nCandidates:\")\nfor c in candidates:\n    print(\" \", c, \"exists=\", Path(c).exists())\n\n# Try running conda directly if we found one\nconda = next((c for c in candidates if Path(c).exists()), None) or shutil.which(\"conda\")\nprint(\"\\nResolved conda:\", conda)\n\nif conda:\n    p = subprocess.run([conda, \"--version\"], capture_output=True, text=True)\n    print(\"conda --version rc:\", p.returncode)\n    print(\"stdout:\", p.stdout.strip())\n    print(\"stderr:\", p.stderr.strip())\nelse:\n    print(\"No conda found in this process.\")\n\n\nPackage Imports\n\n# --- Standard library ---\nimport importlib.metadata\nimport importlib\nimport json\nimport os\nimport platform\nimport random\nimport re\nimport shutil\nimport subprocess\nimport sys\nimport tarfile\nfrom pathlib import Path\nfrom urllib.parse import urlsplit\n\n# --- Third-party ---\nimport itables\nimport numpy as np\nimport pandas as pd\nimport requests\nimport sklearn\nimport yaml\nfrom IPython.display import Markdown, display\nfrom ydata_profiling import ProfileReport\n\n# --- Currently Testing ---\nimport time\nimport cbioportal\nfrom cbioportal.rest import ApiException\nfrom pprint import pprint\n\n# --- Local / project ---\nimport config\n\nimportlib.reload(config)\n\n\n\nCustom Objects\n\nfrom dataclasses import dataclass, field\nfrom typing import Optional, List, Dict\n\n@dataclass\nclass CancerStudy:\n    # Core identity\n    study_id: str\n    study_name: str\n    description: Optional[str]\n\n    # Cancer classification\n    cancer_type_id: Optional[str]\n    cancer_type_name: Optional[str]\n\n    # Clinical summary\n    sample_count: Optional[int] = None\n    patient_count: Optional[int] = None\n\n    # Data modalities present\n    data_types: List[str] = field(default_factory=list)\n\n    # Provenance\n    reference: Optional[str] = None\n    citation: Optional[str] = None\n    pmid: Optional[str] = None\n\n    # Internal / system metadata\n    source_url: Optional[str] = None\n    raw_meta: Dict[str, str] = field(default_factory=dict)\n\n\n\nParameters\n\n\n\n\n\n\nImportant\n\n\n\nMost parameters are defined in the config.py file, and will eventually be part of environment variables\n\n\n\n# Parameters\nRANDOM_SEED = 3660\n\n\n\nPackage Defaults / Options\n\n# ITables\n# itables.init_notebook_mode()\n\n# Pandas\npd.set_option(\"display.max_rows\", 30)\npd.set_option(\"display.max_columns\", 50)\npd.set_option(\"display.width\", 120)\npd.set_option(\"display.max_colwidth\", 60)\n\n# Randomness\nos.environ[\"PYTHONHASHSEED\"] = str(RANDOM_SEED)\nrandom.seed(RANDOM_SEED)\nnp.random.seed(RANDOM_SEED)\n# Note for later:\n# - use random_state=RANDOM_SEED in sklearn models\n# - TSNE(random_state=RANDOM_SEED)\n# - train_test_split(..., random_state=RANDOM_SEED)\n\n# Others \n# ...\n\n\n\nHelper Functions\n\ndef download_and_extract_studies(*study_ids: str) -&gt; list[Path]:\n    return [_download_and_extract_study(study) for study in study_ids]\n\ndef _download_and_extract_study(study_id: str):\n    url = f\"{config.DATAHUB_BASE}/{study_id}.tar.gz\"\n    dataset_file = download_dataset(url)\n    dataset_path = extract_dataset(dataset_file)\n    return dataset_path\n\ndef download_dataset(url, /, *, folder: Path = config.DEFAULT_DATASET_DOWNLOAD_FOLDER, force: bool = False) -&gt; Path:\n    folder.mkdir(parents=True, exist_ok=True)\n    \n    filename = Path(urlsplit(url).path).name\n    target = folder / filename\n\n    if force or not target.exists():\n        response = requests.get(url, stream=True)\n        response.raise_for_status()\n        \n        with target.open(\"wb\") as f:\n            for chunk in response.iter_content(chunk_size=8192):\n                f.write(chunk)\n        \n    return target\n\ndef extract_dataset(file: Path, /, *, folder: Path = config.DEFAULT_DATASET_EXTRACT_FOLDER, force: bool = False) -&gt; Path:\n    base_name = file.name.removesuffix(\".tar.gz\")\n    extract_path = folder / base_name\n    \n    folder.mkdir(parents=True, exist_ok=True)\n\n    if force or not extract_path.exists():\n        with tarfile.open(file, \"r:gz\") as tar:\n            tar.extractall(folder)\n\n    return extract_path\n\n\n\nEnvironment\nChecks\n\n# ---------- helpers ----------\n\ndef _run(cmd: list[str]) -&gt; tuple[int, str, str]:\n    p = subprocess.run(cmd, capture_output=True, text=True)\n    return p.returncode, p.stdout, p.stderr\n\ndef _canonical(name: str) -&gt; str:\n    return re.sub(r\"[-_.]+\", \"-\", name).lower().strip()\n\ndef read_environment_yml(path: str | Path = \"environment.yml\"):\n    \"\"\"\n    Parse environment.yml into:\n      - conda_chosen: conda deps declared in environment.yml (name -&gt; version/constraint/None)\n      - pip_chosen: pip deps declared under `- pip:` in environment.yml (name -&gt; version/constraint/None)\n    Notes:\n      - Handles conda pins like `name`, `name=ver`, `name=ver=build`\n      - Handles constraints like `python&gt;=3.11`, `numpy&lt;2`\n      - Normalizes accidental leading '=' in version strings (e.g., '=1.2.3')\n    \"\"\"\n    with open(path, \"r\", encoding=\"utf-8\") as f:\n        data = yaml.safe_load(f) or {}\n\n    conda_chosen: dict[str, str | None] = {}\n    pip_chosen: dict[str, str | None] = {}\n\n    deps = data.get(\"dependencies\", []) or []\n    for dep in deps:\n        if isinstance(dep, str):\n            s = dep.strip()\n            if not s:\n                continue\n\n            # constraint case: python&gt;=3.11, numpy&lt;2, etc.\n            m = re.match(r\"^([A-Za-z0-9_.-]+)\\s*([&lt;&gt;=!~].+)$\", s)\n            if m:\n                conda_chosen[_canonical(m.group(1))] = m.group(2).strip()\n                continue\n\n            # conda pins can be: name, name=ver, name=ver=build\n            parts = s.split(\"=\")\n            name = _canonical(parts[0])\n            ver = parts[1] if len(parts) &gt;= 2 else None\n            if ver is not None:\n                ver = ver.strip()\n                if ver.startswith(\"=\") and not ver.startswith(\"==\"):\n                    ver = ver.lstrip(\"=\")\n            conda_chosen[name] = ver\n\n        elif isinstance(dep, dict) and \"pip\" in dep:\n            for p in dep.get(\"pip\", []) or []:\n                ps = str(p).strip()\n                if not ps:\n                    continue\n                if \"==\" in ps:\n                    pkg, ver = ps.split(\"==\", 1)\n                    pip_chosen[_canonical(pkg)] = ver.strip()\n                else:\n                    # store non-exact constraint as-is (&gt;=, &lt;=, ~=, etc.)\n                    pkg = re.split(r\"[&lt;&gt;=!~]\", ps, maxsplit=1)[0].strip()\n                    constraint = ps[len(pkg):].strip() or None\n                    pip_chosen[_canonical(pkg)] = constraint\n\n    return data, conda_chosen, pip_chosen\n\n\ndef _conda_cmd() -&gt; list[str] | None:\n    \"\"\"\n    Find conda.exe even when it's not on PATH (common for notebooks on Windows).\n\n    Priority:\n      1) CONDA_EXE env var (if set)\n      2) PATH lookup (shutil.which(\"conda\"))\n      3) Derive from CONDA_PREFIX (Windows Anaconda layout):\n         CONDA_PREFIX = ...\\\\anaconda3\\\\envs\\\\&lt;env&gt;\n         conda.exe    = ...\\\\anaconda3\\\\Scripts\\\\conda.exe\n    \"\"\"\n    # 1) explicit env var (often not set in notebooks)\n    conda_exe = os.getenv(\"CONDA_EXE\")\n    if conda_exe and Path(conda_exe).exists():\n        return [conda_exe]\n\n    # 2) PATH lookup\n    which = shutil.which(\"conda\")\n    if which:\n        return [which]\n\n    # 3) derive from CONDA_PREFIX on Windows\n    conda_prefix = os.getenv(\"CONDA_PREFIX\")\n    if conda_prefix:\n        p = Path(conda_prefix)\n        # Typical: .../anaconda3/envs/&lt;env&gt; -&gt; base is parent of \"envs\"\n        if p.parent.name.lower() == \"envs\":\n            base = p.parents[1]\n        else:\n            # Sometimes CONDA_PREFIX might be the base env itself\n            base = p\n        candidate = base / \"Scripts\" / \"conda.exe\"\n        if candidate.exists():\n            return [str(candidate)]\n\n    return None\n\n\ndef conda_available() -&gt; bool:\n    cmd = _conda_cmd()\n    if not cmd:\n        return False\n    try:\n        subprocess.run(cmd + [\"--version\"], capture_output=True, text=True, check=True)\n        return True\n    except Exception:\n        return False\n\n\ndef get_conda_installed_versions_strict() -&gt; dict[str, str]:\n    cmd = _conda_cmd()\n    if not cmd:\n        raise FileNotFoundError(\"Could not find conda executable...\")\n\n    prefix = os.getenv(\"CONDA_PREFIX\")\n    if not prefix:\n        raise RuntimeError(\"CONDA_PREFIX is not set; cannot target env.\")\n\n    proc = subprocess.run(\n        cmd + [\"list\", \"--json\", \"--prefix\", prefix],\n        capture_output=True,\n        text=True,\n    )\n    if proc.returncode != 0:\n        raise RuntimeError(f\"conda list failed:\\nSTDOUT:\\n{proc.stdout}\\nSTDERR:\\n{proc.stderr}\")\n\n    items = json.loads(proc.stdout)\n    out = {}\n    for it in items:\n        name = (it.get(\"name\") or \"\").strip().lower()\n        ver = (it.get(\"version\") or \"\").strip()\n        if name and ver:\n            out[name] = ver\n\n    out[\"python\"] = sys.version.split()[0]\n    return out\n\ndef get_conda_chosen_from_history() -&gt; dict[str, str | None]:\n    \"\"\"\n    Packages explicitly requested in this env (best proxy):\n    `conda env export --from-history [--prefix ...]`\n\n    Returns: canonical_name -&gt; constraint/pin/None\n      - Handles pins:   name, name=1.2.3, name=1.2.3=build\n      - Handles constraints: name&lt;2, name&gt;=3.11, name ~=1.4, etc.\n    \"\"\"\n    cmd = _conda_cmd()\n    if not cmd:\n        return {}\n\n    # Prefer CONDA_PREFIX if available; otherwise fall back to interpreter prefix\n    prefix = os.getenv(\"CONDA_PREFIX\") or str(Path(sys.executable).resolve().parent.parent)\n\n    proc = subprocess.run(\n        cmd + [\"env\", \"export\", \"--from-history\", \"--prefix\", prefix],\n        capture_output=True,\n        text=True,\n    )\n    if proc.returncode != 0:\n        # If conda isn't available in this context, just return empty (don't blow up rendering)\n        return {}\n\n    data = yaml.safe_load(proc.stdout) or {}\n    deps = data.get(\"dependencies\", []) or []\n\n    chosen: dict[str, str | None] = {}\n\n    for dep in deps:\n        if not isinstance(dep, str):\n            continue\n        s = dep.strip()\n        if not s:\n            continue\n\n        # constraint case: python&gt;=3.11, setuptools&lt;80, numpy!=2.0, etc.\n        m = re.match(r\"^([A-Za-z0-9_.-]+)\\s*([&lt;&gt;=!~].+)$\", s)\n        if m:\n            chosen[_canonical(m.group(1))] = m.group(2).strip()\n            continue\n\n        # pin case: name, name=ver, name=ver=build\n        parts = s.split(\"=\")\n        name = _canonical(parts[0])\n        ver = parts[1].strip().lstrip(\"=\") if len(parts) &gt;= 2 else None\n        chosen[name] = ver\n\n    return chosen\n\n\n\ndef get_pip_installed_all() -&gt; dict[str, str]:\n    \"\"\"\n    pip list as json; best effort even inside conda env.\n    \"\"\"\n    rc, out, err = _run([sys.executable, \"-m\", \"pip\", \"list\", \"--format=json\"])\n    if rc != 0:\n        return {}\n    items = json.loads(out)\n    return {_canonical(it[\"name\"]): it[\"version\"] for it in items}\n\n\ndef version_status(expected: str | None, installed: str | None) -&gt; str:\n    if installed is None:\n        return \"MISSING\"\n    if expected is None:\n        return \"OK (un-pinned)\"\n\n    expected = expected.strip()\n\n    # Treat \"=1.2.3\" as an exact pin (common accidental format)\n    if expected.startswith(\"=\") and not expected.startswith(\"==\"):\n        expected = expected.lstrip(\"=\")\n\n    # True constraints (&gt;=, &lt;=, ==, ~=, etc.)\n    if expected and expected[0] in \"&lt;&gt;!~\" or expected.startswith(\"==\"):\n        return \"CHECK (constraint)\"\n\n    if expected.endswith(\".*\"):\n        return \"OK\" if installed.startswith(expected[:-1]) else \"MISMATCH\"\n\n    return \"OK\" if installed == expected else \"MISMATCH\"\n\n\n\n# ---------- run ----------\n\nenv_data, yml_conda_chosen, yml_pip_chosen = read_environment_yml(\"environment.yml\")\n\n# Capture interpreter details (your \"custom interpreter\" concern)\ninterpreter_rows = [\n    {\"Key\": \"sys.executable\", \"Value\": sys.executable},\n    {\"Key\": \"sys.version\", \"Value\": sys.version},\n]\nif os.getenv(\"CONDA_PREFIX\"):\n    interpreter_rows.append({\"Key\": \"CONDA_PREFIX\", \"Value\": os.getenv(\"CONDA_PREFIX\")})\ndf_interpreter = pd.DataFrame(interpreter_rows)\ndisplay(df_interpreter)\n\n# Get actuals\ntry:\n    conda_installed = get_conda_installed_versions_strict() if conda_available() else {}\nexcept Exception as e:\n    print(\"‚ö†Ô∏è Could not read conda installed packages:\", e)\n    conda_installed = {}\n\nconda_history_chosen = get_conda_chosen_from_history() if conda_available() else {}\npip_installed = get_pip_installed_all()\n\nrows: list[dict] = []\n\ndef add_manager_rows(\n    manager: str,\n    chosen_map: dict[str, str | None],\n    installed_versions: dict[str, str],\n):\n    chosen_set = set(chosen_map.keys())\n\n    # chosen packages (source of truth = environment.yml)\n    for pkg in sorted(chosen_map.keys()):\n        exp = chosen_map[pkg]\n        got = installed_versions.get(pkg)\n        status = version_status(exp, got)\n        rows.append({\n            \"Manager\": manager,\n            \"Package\": pkg,\n            \"Chosen?\": True,\n            \"Expected (environment.yml)\": exp if exp is not None else \"(un-pinned)\",\n            \"Installed\": got if got is not None else \"(not installed)\",\n            \"Status\": status,\n        })\n\n    # dependencies (installed but not chosen)\n    for pkg in sorted(set(installed_versions.keys()) - chosen_set):\n        got = installed_versions.get(pkg)\n        rows.append({\n            \"Manager\": manager,\n            \"Package\": pkg,\n            \"Chosen?\": False,\n            \"Expected (environment.yml)\": \"(dependency)\",\n            \"Installed\": got,\n            \"Status\": \"INFO (dependency)\",\n        })\n\n# Conda & Pip rows\nadd_manager_rows(\"conda\", yml_conda_chosen, conda_installed)\nadd_manager_rows(\"pip\", yml_pip_chosen, pip_installed)\n\ndf = pd.DataFrame(rows)\n\n# Helpful sorting: chosen first, then manager, then package\ndf = df.sort_values(by=[\"Chosen?\", \"Manager\", \"Package\"], ascending=[False, True, True]).reset_index(drop=True)\ndisplay(df)\n\n# Summary counts for quick signal\nsummary = df.groupby([\"Manager\", \"Status\"]).size().reset_index(name=\"Count\")\ndisplay(summary)\n\n# Extra: show \"explicit conda-history packages missing from environment.yml\"\nextra_explicit = []\nif conda_history_chosen:\n    for pkg in sorted(set(conda_history_chosen.keys()) - set(yml_conda_chosen.keys())):\n        extra_explicit.append({\n            \"Package\": pkg,\n            \"From conda history\": conda_history_chosen[pkg],\n            \"In environment.yml?\": \"NO\",\n        })\n\ndf_extra_explicit = pd.DataFrame(extra_explicit)\nif not df_extra_explicit.empty:\n    print(\"‚ö†Ô∏è Packages explicitly requested in this conda env (history) but missing from environment.yml:\")\n    display(df_extra_explicit)\nelse:\n    print(\"‚úÖ No extra explicit conda-history packages missing from environment.yml (or conda history unavailable).\")\n\n\n\n\n\n\n\n\nKey\nValue\n\n\n\n\n0\nsys.executable\nC:\\dev\\bijan-projects\\genomics-data-mining\\env\\python.exe\n\n\n1\nsys.version\n3.11.14 | packaged by conda-forge | (main, Jan 26 2026, ...\n\n\n2\nCONDA_PREFIX\nC:\\dev\\bijan-projects\\genomics-data-mining\\env\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nManager\nPackage\nChosen?\nExpected (environment.yml)\nInstalled\nStatus\n\n\n\n\n0\nconda\ncbioportal\nTrue\n(un-pinned)\n1.0.0\nOK (un-pinned)\n\n\n1\nconda\nipykernel\nTrue\n(un-pinned)\n7.2.0\nOK (un-pinned)\n\n\n2\nconda\nipywidgets\nTrue\n(un-pinned)\n8.1.8\nOK (un-pinned)\n\n\n3\nconda\nitables\nTrue\n(un-pinned)\n2.7.0\nOK (un-pinned)\n\n\n4\nconda\njupyterlab\nTrue\n(un-pinned)\n4.5.4\nOK (un-pinned)\n\n\n...\n...\n...\n...\n...\n...\n...\n\n\n384\npip\nwidgetsnbextension\nFalse\n(dependency)\n4.0.15\nINFO (dependency)\n\n\n385\npip\nwin-inet-pton\nFalse\n(dependency)\n1.1.0\nINFO (dependency)\n\n\n386\npip\nwordcloud\nFalse\n(dependency)\n1.9.6\nINFO (dependency)\n\n\n387\npip\nydata-profiling\nFalse\n(dependency)\n0.0.dev0\nINFO (dependency)\n\n\n388\npip\nzipp\nFalse\n(dependency)\n3.23.0\nINFO (dependency)\n\n\n\n\n389 rows √ó 6 columns\n\n\n\n\n\n\n\n\n\n\nManager\nStatus\nCount\n\n\n\n\n0\nconda\nCHECK (constraint)\n1\n\n\n1\nconda\nINFO (dependency)\n219\n\n\n2\nconda\nOK (un-pinned)\n16\n\n\n3\npip\nINFO (dependency)\n153\n\n\n\n\n\n\n\n‚ö†Ô∏è Packages explicitly requested in this conda env (history) but missing from environment.yml:\n\n\n\n\n\n\n\n\n\nPackage\nFrom conda history\nIn environment.yml?\n\n\n\n\n0\nsetuptools[version\n'&lt;\nNO"
  },
  {
    "objectID": "index.html#data-acquisition",
    "href": "index.html#data-acquisition",
    "title": "Genomics Data Mining",
    "section": "Data Acquisition",
    "text": "Data Acquisition\n\nhtml`\n&lt;div class=\"section-div\"&gt;\n  &lt;div&gt;Setup&lt;/div&gt;\n  &lt;div class=\"current\"&gt;Data Acquisition&lt;/div&gt;\n  &lt;div&gt;Data Understanding&lt;/div&gt;\n  &lt;div&gt;Data Cleaning&lt;/div&gt;\n  &lt;div&gt;Dimension Reduction&lt;/div&gt;\n  &lt;div&gt;Statistical Modelling&lt;/div&gt;\n  &lt;div&gt;Conclusions&lt;/div&gt;\n&lt;/div&gt;\n`\n\n\n\n\n\n\nWe use the cBioPortal to gather data about what is available.\n\ncBioPortal\n\nCancer Types\n\n# Cancer Types API\ncancer_types_api_config = cbioportal.Configuration()\ncancer_types_api_instance = cbioportal.CancerTypesApi(cbioportal.ApiClient(cancer_types_api_config))\n\ncbioportal_cancer_types = cancer_types_api_instance.get_all_cancer_types_using_get()\ncbioportal_cancer_types = pd.DataFrame([item.to_dict() for item in cbioportal_cancer_types])\n\nitables.show(\n    cbioportal_cancer_types\n)\n\n\n\n    \n    \n    \n        \n        \n        \n        \n        \n        \n        \n        \n    \n    \n   \n    \n      \n  \n        \n    \n    \n  \n        \n    \n    \n  \n        \n    \n      \n  \n        \n            \n                \n                \n            \n\n            \n                \n                \n            \n\n            \n                \n                \n            \n\n            \n                \n                \n            \n\n            \n                \n                \n            \n        \n    \n\n\n    Loading ITables v2.7.0 from the internet...\n    (need help?)\n    \n\n\n\n\n\n\nStudies\n\n# Studies API\nstudies_api_instance = cbioportal.StudiesApi()\n\ncbioportal_studies = studies_api_instance.get_all_studies_using_get()\ncbioportal_studies = pd.DataFrame([item.to_dict() for item in cbioportal_studies])\n\nitables.show(\n    cbioportal_studies\n)\n\n\n\n    \n    \n    \n        \n        \n        \n        \n        \n        \n        \n        \n    \n    \n   \n    \n      \n  \n        \n    \n    \n  \n        \n    \n    \n  \n        \n    \n      \n  \n        \n            \n                \n                \n            \n\n            \n                \n                \n            \n\n            \n                \n                \n            \n\n            \n                \n                \n            \n\n            \n                \n                \n            \n        \n    \n\n\n    Loading ITables v2.7.0 from the internet...\n    (need help?)\n    \n\n\n\n\n\n\nClinical Attributes\n\n# Clinical Attributes API\n\nlgg_clinical_attributes = cbioportal.ClinicalAttributesApi().get_all_clinical_attributes_in_study_using_get('lgg_tcga_pan_can_atlas_2018')\nlgg_clinical_attributes = pd.DataFrame([item.to_dict() for item in lgg_clinical_attributes])\n\nitables.show(\n    lgg_clinical_attributes\n)\n\n\n\n    \n    \n    \n        \n        \n        \n        \n        \n        \n        \n        \n    \n    \n   \n    \n      \n  \n        \n    \n    \n  \n        \n    \n    \n  \n        \n    \n      \n  \n        \n            \n                \n                \n            \n\n            \n                \n                \n            \n\n            \n                \n                \n            \n\n            \n                \n                \n            \n\n            \n                \n                \n            \n        \n    \n\n\n    Loading ITables v2.7.0 from the internet...\n    (need help?)\n    \n\n\n\n\n\n\n\nDownload and Extract\nThe Brain Lower Grade Glioma (TCGA, PanCancer Atlas) dataset was obtained from the cBioPortal for Cancer Genomics. The dataset was downloaded as a compressed tarball containing clinical, molecular, and metadata files.\nDataset: Brain Lower Grade Glioma (TCGA, PanCancer Atlas)\nSource: https://www.cbioportal.org/\nFile: lgg_tcga_pan_can_atlas_2018.tar.gz\n\nstudy_paths = download_and_extract_studies(\n    \"lgg_tcga_pan_can_atlas_2018\",\n    \"lgg_ucsf_2014\"\n)\nstudy_paths\n\n[WindowsPath('C:/dev/bijan-projects/genomics-data-mining/data/external/extracted/lgg_tcga_pan_can_atlas_2018'),\n WindowsPath('C:/dev/bijan-projects/genomics-data-mining/data/external/extracted/lgg_ucsf_2014')]\n\n\n\n\n\n\n\n\nNotecBioPortal Downloading\n\n\n\nThere is extensive documentation for how to download from cBioPortal. This includes manually through the browser, or with an API. https://docs.cbioportal.org/downloads/\n\n\n\n\nData Loading\nUsing information from the cBioPortal Summary tab and the downloaded data files, the following provides a high-level overview of the dataset, including patient counts, molecular data availability, mutation frequencies, and survival information.\n\ndef describe_dataframe_table(df: pd.DataFrame) -&gt; pd.DataFrame:\n    rows = []\n\n    for col in df.columns:\n        s = df[col]\n\n        row = {\n            \"Column Name\": col,\n            \"Column Type\": str(s.dtype),\n            \"Non-Null Count\": s.notna().sum(),\n            \"Missing Count\": s.isna().sum(),\n        }\n\n        if pd.api.types.is_numeric_dtype(s):\n            row.update({\n                \"Data Kind\": \"Numeric\",\n                \"Min\": s.min(),\n                \"Max\": s.max(),\n                \"Categories\": None,\n            })\n        else:\n            row.update({\n                \"Data Kind\": \"Categorical\",\n                \"Min\": None,\n                \"Max\": None,\n                \"Categories\": \", \".join(map(str, s.dropna().unique()[:10])),\n            })\n\n        rows.append(row)\n\n    return pd.DataFrame(rows)\n\n\n\nPatientClinical SampleMRNA Seq\n\n\n\nclinical_patient_file = Path(\"data/external/extracted/lgg_tcga_pan_can_atlas_2018/data_clinical_patient.txt\")\n\ndf_clinical_patients = pd.read_csv(clinical_patient_file, sep=\"\\t\", comment=\"#\")\n\ndescribed_df_clinical_patients = describe_dataframe_table(df_clinical_patients)\n\n\nitables.show(\n    described_df_clinical_patients,\n    paging=False,\n    text_in_header_can_be_selected=False,\n    columnControl=[\"order\", \"colVisDropdown\", \"searchDropdown\"],\n    ordering={\"indicators\": False, \"handler\": False}\n)\n\n\n\n    \n    \n    \n        \n        \n        \n        \n        \n        \n        \n        \n    \n    \n   \n    \n      \n  \n        \n    \n    \n  \n        \n    \n    \n  \n        \n    \n      \n  \n        \n            \n                \n                \n            \n\n            \n                \n                \n            \n\n            \n                \n                \n            \n\n            \n                \n                \n            \n\n            \n                \n                \n            \n        \n    \n\n\n    Loading ITables v2.7.0 from the internet...\n    (need help?)\n    \n\n\n\n\n\n\n\nclinical_sample_file = Path(\"data/external/extracted/lgg_tcga_pan_can_atlas_2018/data_clinical_patient.txt\")\n\n\n\ndf_clinical_sample = pd.read_csv(clinical_sample_file, sep=\"\\t\", comment=\"#\")\n\n\n\n\nmrna_seq_file = Path(\"data/external/extracted/lgg_tcga_pan_can_atlas_2018/data_mrna_seq_v2_rsem.txt\")\n\n\ndf_mrna_seq = pd.read_csv(mrna_seq_file, sep=\"\\t\", comment=\"#\")\n\nitables.show(\n    df_mrna_seq\n)\n\n# expr = df.iloc[:, 2:]\n\n# gene_summary = pd.DataFrame({\n#     \"mean\": expr.mean(axis=1),\n#     \"median\": expr.median(axis=1),\n#     \"std\": expr.std(axis=1),\n#     \"variance\": expr.var(axis=1),\n#     \"nonzero_fraction\": (expr &gt; 0).mean(axis=1)\n# })\n\n# gene_summary.head()\n\n\n\n    \n    \n    \n        \n        \n        \n        \n        \n        \n        \n        \n    \n    \n   \n    \n      \n  \n        \n    \n    \n  \n        \n    \n    \n  \n        \n    \n      \n  \n        \n            \n                \n                \n            \n\n            \n                \n                \n            \n\n            \n                \n                \n            \n\n            \n                \n                \n            \n\n            \n                \n                \n            \n        \n    \n\n\n    Loading ITables v2.7.0 from the internet...\n    (need help?)\n    \n\n\n\n\n\n\n\n\n\n\nTODO: data_clinical_sample.txt\n\n\nTODO: Summarize the 3 df‚Äôs\n\n\nTODO:\nThesse are some words in this section"
  },
  {
    "objectID": "index.html#data-understanding",
    "href": "index.html#data-understanding",
    "title": "Genomics Data Mining",
    "section": "Data Understanding",
    "text": "Data Understanding\n\nhtml`\n&lt;div class=\"section-div\"&gt;\n  &lt;div&gt;Setup&lt;/div&gt;\n  &lt;div&gt;Data Acquisition&lt;/div&gt;\n  &lt;div class=\"current\"&gt;Data Understanding&lt;/div&gt;\n  &lt;div&gt;Data Cleaning&lt;/div&gt;\n  &lt;div&gt;Dimension Reduction&lt;/div&gt;\n  &lt;div&gt;Statistical Modelling&lt;/div&gt;\n  &lt;div&gt;Conclusions&lt;/div&gt;\n&lt;/div&gt;\n`\n\n\n\n\n\n\n\nReview\nDNA has many Genes (i.e., regions) A gene is a part of the DNA that does something, and is defined by specific coordinates (one start, and one end) In order for those recipes to do anything, the DNA is copied to RNA, in a process called transcription. This RNA is called ‚ÄúPre-mRNA (Precursor mRNA or heterogenous nuclear RNA: hnRNA)‚Äù The Pre-mRNA is processed by removing certain parts (slicing), adding stuff to one end (capping), and adding other stuff to the other end (polyadenylation), which then makes it ‚ÄúMature mRNA‚Äù (we‚Äôll just call this mRNA from now). ‚Ä¶ in cellular biology, this would then go and do things, perhaps make proteins ‚Ä¶\n\n\nRNA Sequencing\nWe take our sample and turn Mature mRNA into RNA fragments, in a process called fragmentation. Then, with turn those RNA fragments into cDNA fragments, in a process called reverse transcription. This all goes into a High-throughput sequencing machine to give us sequences/reads of every fragment. This will be an ordered list of the chemicals (A C G T) ?? Do we read the RNA or the c-DNA strand\nMajor Data Point 1: We now have a count of all the fragments (and what they are)\nAll of these reads need to get aligned back to the original gene.\n\n\nProblems\n\nDifferent versions of Mature mRNA (which are referred to as an ‚Äúisoform‚Äù) can happen because of an issue during the processing from Pre-mRNA to Mature mRNA including:\n\nAlternative transcript initiation\nAlternative 5‚Äô splice site\nAltertiave 3‚Äô splice site\nSkipped exon\nAlternative polyadenylation\n‚Ä¶ others\n\nIt is expensive and takes a long time to do really long reads (e.g., the whole gene), which is why we need to fragment the mRNA into smaller pieces.\n\nThis means that we might not always capture all the different isoforms.\n\nFragments might align to more than one isoform, or to a different gene.\n\n\n\nGoal\nExpression Analysis, estimate a transcriptome, the set of all expressed transcripts and their frequencies in a cell at a given time.\n\nWe can measure/calculate the relative expression (i.e., frequency) of two things in our sample:\n\nTranscripts (i.e., What proportion of the sample was expressed by a specific isoform, by transcripts?)\n\ne.g., There are a total of 100 transcripts in the whole sample. Isoform AAA1 was expressed by 88 of them.\n\nNucleotides (i.e., What proportion of the sample was expressed by a specific isoform, by nucleotides?)\n\ne.g., There are a total of 1,000,000 nucleotides in the whole sample. Isoform BBB2 was expressed by 500,000 of them.\n\n\n\n\n\nSomethingsomething\nDefinitions All definitions are framed for cBioPortal, the software system (which includes a website, and database) for interactive exploration of multidimensional cancer genomics data sets.\n\nTCGA\n\nThe Cancer Genome Atlas, a project that profiles specific cancer types to understand their individual molecular landscape.\n\nPanCanAtlas\n\na Pan-Cancer Initiative that took all 33 TCGA cancer types and analyzed them together to compare molecular similarities and differences.\n\nStudy\n\nOften identified by its acronym (e.g., TCGA-LGG) represents the specific tumour cohort that was analyzed.\n\nOntology\n\na set of concepts and categories in a subject area or domain that shows their properties and the relations between them\n\nOncoTree\n\nthe cancer type ontology used by cBioPortal, which has has a root node of Tissue, so Level 1 would be all the Tissue Sites, then they are categorized by cancer types.\n\n\ncBioPortal Data Model\nDatabase Studies Clinical Data Samples Sample Lists Patients Namespace Attributes Mutations Molecular Data Gene Panel Data Discrete Copy Number Alterations Molecular Profiles Genes Generic Assays Generic Assay Data Gene Panels Copy Number Segments Clinical Attributes Cancer Types\nDatabase, the Dataset, the set of files for a particular study Data Type: Clinical Data Type: Molecular Sequencing RNA Sequencing RSEM\nRSEM defines the following;\nFor isoform \\(i\\), \\(\\nu_i\\), the fraction of nucleotides made up by a given gene or isoform \\[\n\\nu_i = \\frac{\\tau_i\\ell_i}{\\sum_j\\tau_j\\ell_j}\n\\]\n\\(\\tau_i\\), the fraction of transcripts made up by a given gene or isoform \\[\n\\tau_i = \\frac{\\nu_i}{\\ell_i}\\left(\\sum_j\\frac{\\nu_j}{\\ell_j}\\right)^{-1}\n\\]\nwhere \\(\\ell_i\\) is the length, in nucleotides, of isoform \\(i\\).\nThe probability that the read sequence \\[\nP(r|\\theta) = \\prod_{n=1}^N\\sum_{i=0}^M\\theta_i P(r_n|G_n=i)\n\\]\nEM Algorithm - An iterative method to find (local) maximum likelihood estimates of parameters in statistical models, where the model depends on unobserved latent variables.\nRSEM Model - Generates reads from a combination of isoform, start position, and orientation - \\(N\\) the number of reads generated (independent and identically distributed) - i.i.d is an assumption that is supported by uniform sampling, massive parallelization and high depth, random fragmentation, poisson/negative binomial approximation accounting for dispersion - i.i.d. for rna-seq is rarely perfect, but is helpful for when we do differential expression analysis - \\(L\\) the length of reads - Random Variables - \\(R_n\\), read sequences (i.e., observed data) - Latent Random Variables - \\(G_n\\), isoform (from which the read came from) - \\(S_n\\), start position (from which the read came from) - \\(O_n\\), orientation (from which the read came from) - Parameters - \\(\\theta = [\\theta_0, ... , \\theta_M]\\), the expression levels - We assume \\(M\\), all possible isoforms in a transcriptome, is given\nMore Details - \\(G_n \\in \\{0, ..., M\\}\\), where \\(0\\) represents a ‚Äònoise‚Äô isoform, which generates reads that do not map to known isoforms. - The probability of any given isoform is determined when the expression levels for that isoform equals 1. - \\(P(G_n=i | \\theta) = \\theta_i \\text{  where  } \\sum_i\\theta_i = 1\\) - \\(S_n \\in \\{1, ..., \\text{max}_i\\ell_i}\\), where \\(\\ell_i\\) is the length of isoform \\(i\\) - \\(P(S_{n=j} | G_{n=i})\\) is called the read start position distribution (RPSD) - \\(P(S_{n=j} | G_{n=i}) = \\ell^{-1}_i\\), for reads generated uniformly across transcripts and mRNA with poly(A) tails - The other models are not shown, because the important part is the relationship with length - \\(O_n \\in \\{0, 1\\}\\) - 0 indicating that the sequence of read n is in the same orientation as that of its parent isoform - 1 indicating thet the sequence of read n is the reverse complement of its parent isoform - \\(R_n\\) summarizes the hidden random variables for the \\(n\\)-th read with a set of indicator random variables - \\(Z_{nijk} \\text{  where  } Z_{njk} = 1 \\text{ if } (G_n, S_n, O_n) = (i, j, k)\\) - Therefore, the conditional probability of a read sequence derived from an isoform (other than the noise isoform) is given by\n\\[\nP(R_n = \\rho | Z_{njk} = 1) = \\begin{cases}\n    \\prod_{t=1}^L w_t(\\rho_t , \\gamma_{j+t-1}^i) \\qquad k=0 \\\\\n    \\prod_{t=1}^L w_t(\\rho_t , \\bar{\\gamma}_{j+t-1}^i) \\qquad k=1\n\\end{cases}\n\\]\n\n\\(\\gamma^i\\) is the sequence of the isoform \\(i\\) and \\(\\bar{\\gamma}^i\\) is its reverse complement\n\\(w_t(a,b)\\) is a position-specific substitution matrix, where the value is the probability that we observe character \\(a\\) as position \\(t\\) of the read given that the corresponding character in the reference isoform sequence is \\(b\\)\n\nExpresseions at the gene level is simply the sum of the expression of possible isoforms.\nNOTE: There is some really interesting Maths regarding the RSEM algorithm alternating between the E-step and the M-step that results in the concavity of the log likelihood function (i.e., guaranteed to reach a global maximum).\nWhat the bloody hell does this even mean?\nWe‚Äôre looking at ‚Äúgenes.normalized_results‚Äù so it‚Äôs going to be the sum of isoforms\n\nRNASeqV2 = Processed using RSEM (RNA-Seq by Expectation-Maximization)\n\nSpecifically data_mrna_seq_v2_rsem.txt = to the rsem.genes.normalized_results file from TCGA\n\nRSEM calculates the estimated number of reads that aligned to a transcript (i.e., relative expression)\n\nfraction of transcripts\nfraction of nucleotides\n\n\nWhat do the numbers in data_mrna_seq_v2_rsem.txt mean?\n\n1\n\n1"
  },
  {
    "objectID": "index.html#data-cleaning",
    "href": "index.html#data-cleaning",
    "title": "Genomics Data Mining",
    "section": "Data Cleaning",
    "text": "Data Cleaning\n\nhtml`\n&lt;div class=\"section-div\"&gt;\n  &lt;div&gt;Setup&lt;/div&gt;\n  &lt;div&gt;Data Acquisition&lt;/div&gt;\n  &lt;div&gt;Data Understanding&lt;/div&gt;\n  &lt;div class=\"current\"&gt;Data Cleaning&lt;/div&gt;\n  &lt;div&gt;Dimension Reduction&lt;/div&gt;\n  &lt;div&gt;Statistical Modelling&lt;/div&gt;\n  &lt;div&gt;Conclusions&lt;/div&gt;\n&lt;/div&gt;\n`"
  },
  {
    "objectID": "index.html#dimension-reduction",
    "href": "index.html#dimension-reduction",
    "title": "Genomics Data Mining",
    "section": "Dimension Reduction",
    "text": "Dimension Reduction\n\nhtml`\n&lt;div class=\"section-div\"&gt;\n  &lt;div\"&gt;Setup&lt;/div&gt;\n  &lt;div&gt;Data Acquisition&lt;/div&gt;\n  &lt;div&gt;Data Understanding&lt;/div&gt;\n  &lt;div&gt;Data Cleaning&lt;/div&gt;\n  &lt;div class=\"current\"&gt;Dimension Reduction&lt;/div&gt;\n  &lt;div&gt;Statistical Modelling&lt;/div&gt;\n  &lt;div&gt;Conclusions&lt;/div&gt;\n&lt;/div&gt;\n`"
  },
  {
    "objectID": "index.html#statistical-modelling",
    "href": "index.html#statistical-modelling",
    "title": "Genomics Data Mining",
    "section": "Statistical Modelling",
    "text": "Statistical Modelling\n\nhtml`\n&lt;div class=\"section-div\"&gt;\n  &lt;div&gt;Setup&lt;/div&gt;\n  &lt;div&gt;Data Acquisition&lt;/div&gt;\n  &lt;div&gt;Data Understanding&lt;/div&gt;\n  &lt;div&gt;Data Cleaning&lt;/div&gt;\n  &lt;div&gt;Dimension Reduction&lt;/div&gt;\n  &lt;div class=\"current\"&gt;Statistical Modelling&lt;/div&gt;\n  &lt;div&gt;Conclusions&lt;/div&gt;\n&lt;/div&gt;\n`"
  },
  {
    "objectID": "index.html#conclusions",
    "href": "index.html#conclusions",
    "title": "Genomics Data Mining",
    "section": "Conclusions",
    "text": "Conclusions\n\nhtml`\n&lt;div class=\"section-div\"&gt;\n  &lt;div&gt;Setup&lt;/div&gt;\n  &lt;div&gt;Data Acquisition&lt;/div&gt;\n  &lt;div&gt;Data Understanding&lt;/div&gt;\n  &lt;div&gt;Data Cleaning&lt;/div&gt;\n  &lt;div&gt;Dimension Reduction&lt;/div&gt;\n  &lt;div&gt;Statistical Modelling&lt;/div&gt;\n  &lt;div class=\"current\"&gt;Conclusions&lt;/div&gt;\n&lt;/div&gt;\n`"
  },
  {
    "objectID": "index.html#what-we-actually-measured",
    "href": "index.html#what-we-actually-measured",
    "title": "Genomics Data Mining",
    "section": "What We Actually Measured",
    "text": "What We Actually Measured\n\nüîç The Crime Scene (Biological Reality)\n\nTumor tissue contains RNA.\nRNA represents which genes are actively being used.\nWe sequence millions of short fragments (reads).\nEach read is a tiny piece of a transcript."
  },
  {
    "objectID": "index.html#the-reconstruction",
    "href": "index.html#the-reconstruction",
    "title": "Genomics Data Mining",
    "section": "üìñ The Reconstruction",
    "text": "üìñ The Reconstruction\nWe assume all fragments came from a known reference ‚Äúbook‚Äù (the human transcriptome).\nUsing RSEM (RNA-Seq by Expectation Maximization):\n\nReads are probabilistically assigned to transcript isoforms.\nIsoform estimates are aggregated to gene-level estimates.\nValues are corrected for:\n\nGene length\nSequencing depth\nMulti-mapping reads\n\n\nThe result:\n\nA gene-by-sample matrix of estimated transcript abundance."
  },
  {
    "objectID": "index.html#what-each-row-represents",
    "href": "index.html#what-each-row-represents",
    "title": "Genomics Data Mining",
    "section": "üìä What Each Row Represents",
    "text": "üìä What Each Row Represents\nHugo_Symbol\nThe official gene name (e.g., TP53, IDH1).\nEntrez_Gene_Id\nStable numeric gene identifier (database key).\nEach row = one gene.\nEach column = one tumor sample.\nEach value = estimated mRNA abundance for that gene in that tumor."
  },
  {
    "objectID": "index.html#what-the-numbers-mean",
    "href": "index.html#what-the-numbers-mean",
    "title": "Genomics Data Mining",
    "section": "üìà What the Numbers Mean",
    "text": "üìà What the Numbers Mean\n\nContinuous\nNon-negative\nLinear RSEM abundance estimates\nProportional to transcript abundance\nNot raw molecule counts\nNot mutation data\nNot protein levels\n\nIf Gene A = 200 and Gene B = 100 (within a sample):\n‚Üí Gene A has approximately twice the estimated transcript abundance of Gene B.\nBut:\nMagnitude ‚â† importance."
  },
  {
    "objectID": "index.html#what-matters-most",
    "href": "index.html#what-matters-most",
    "title": "Genomics Data Mining",
    "section": "üß† What Matters Most",
    "text": "üß† What Matters Most\n\n1Ô∏è‚É£ Same Gene Across Samples\nBiologically meaningful comparison.\n\n\n2Ô∏è‚É£ Variability Across Tumors\nHigh variance genes ‚Üí informative\nLow variance genes ‚Üí housekeeping / background\n\n\n3Ô∏è‚É£ Expression ‚â† Genome\nWe measured gene expression, not gene presence or mutation."
  },
  {
    "objectID": "index.html#key-vocabulary",
    "href": "index.html#key-vocabulary",
    "title": "Genomics Data Mining",
    "section": "üß¨ Key Vocabulary",
    "text": "üß¨ Key Vocabulary\n\nGene ‚Äì DNA locus that produces RNA.\nIsoform ‚Äì Alternative transcript version of a gene.\nTranscriptome ‚Äì Total RNA expression profile of a sample.\nRSEM ‚Äì Probabilistic transcript quantification method.\nExpected Counts ‚Äì Model-based abundance estimates.\nNormalization ‚Äì Adjusting for technical bias (not biological baseline).\nVariance ‚Äì Spread across samples; often more informative than raw magnitude."
  },
  {
    "objectID": "index.html#the-big-insight",
    "href": "index.html#the-big-insight",
    "title": "Genomics Data Mining",
    "section": "üé≠ The Big Insight",
    "text": "üé≠ The Big Insight\nEach tumor is not just a disease.\nIt is:\n\nA 20,531-dimensional expression profile\ndescribing which biological programs are active.\n\nWe reconstructed the ‚Äúspellbook.‚Äù\nBut the real story lives in:\n\nWhich chapters change.\nWhich remain constant.\nAnd how patterns emerge across tumors."
  },
  {
    "objectID": "index.html#the-important-limitation",
    "href": "index.html#the-important-limitation",
    "title": "Genomics Data Mining",
    "section": "‚ö†Ô∏è The Important Limitation",
    "text": "‚ö†Ô∏è The Important Limitation\nExpression data tells us:\n\nWhat instructions are active.\n\nIt does NOT tell us:\n\nWhy they‚Äôre active.\nWhether they‚Äôre mutated.\nWhether protein levels match.\nWhether the change is causal.\n\nThis is one layer of biology."
  },
  {
    "objectID": "index.html#final-line-for-class",
    "href": "index.html#final-line-for-class",
    "title": "Genomics Data Mining",
    "section": "üî• Final Line for Class",
    "text": "üî• Final Line for Class\n\n‚ÄúWe didn‚Äôt count genes.\nWe counted how loudly each gene was being read.\nAnd in that noise‚Ä¶ the pattern begins to whisper.‚Äù"
  }
]